name: 'PPO'
train_feature_extractor: true
n_steps: 2048
batch_size: 32
ent_coef: 0.0
gamma: 0.99
gae_lambda: 0.95
vf_coef: 0.5
target_kl: null
clip_range: 0.2
bc_mult: 1.
ppg_freq: 8
ppg_epochs: 8
rollout_epochs: 10
pretrain_steps: 30_000

optimizer:
    policy_optimizer:
        eps: 1e-05
        weight_decay: 0.
        gradient_clip_val: 0.5
        lr: 3e-4