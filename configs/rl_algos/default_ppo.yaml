globals:
  device: 'cuda'
  sample_cpu: true
  seed: 42
  n_thread: 1
  n_parallel: 8
  mlp_arch: [128, 128]

env:
  name: maze
  max_path_length: 200
  frame_stack: null
  normalizer_type: "off"
  env_kwargs: null

skill:
  name: 'METRA'
  dim_option: 2
  discrete: false
  unit_length: true
  device: ${globals.device}
  dual_reg: true
  dual_slack: 1e-3
  dual_dist_name: 'one'
  dual_dist: null
  dual_lam: 30
  dual_lr: 1e-4
  target_traj_encoder_coef: 0.8
  trajectory_encoder:
    slot_extractor:
      name: null
    slot_pooler:
      name: null
    dim_option: ${skill.dim_option}
    hidden_sizes: [1024, 1024]
    lr: 1e-4
    nonlinearity: relu
    init_std: 1
    min_std: 1e-6
    max_std: null
    std_parameterization: 'exp'
    bias: True
    spectral_normalization: false

rl_algo:
  name: 'PPO'
  discount: 0.99
  gae_lambda: 0.95
  norm_adv: true
  clip_coef: 0.2
  clip_vloss: true
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: null
  device: ${globals.device}
  policy:
    slot_extractor:
      name: null
    slot_pooler:
      name: null
    name: 'option_policy'
    lr: 3e-4
    std_lr: 3e-04
    dim_option: ${skill.dim_option}
    hidden_sizes: ${globals.mlp_arch}
    hidden_w_init:
      name: orthogonal
    output_w_init:
      name: orthogonal
      std: 0.01
    layer_normalization: false
    nonlinearity: tanh
    distribution:
      name: GlobalStd
      starting_logstd: 0.
      max_logstd: 100
      min_logstd: null
      std_parameterization: exp
      type: PPOTanhNormal
  value:
    slot_extractor:
      name: null
    slot_pooler:
      name: null
    lr: 3e-4
    dim_option: ${skill.dim_option}
    hidden_sizes: ${globals.mlp_arch}
    hidden_w_init:
      name: orthogonal
    output_w_init:
      name: orthogonal
      std: 1.
    nonlinearity: tanh
    layer_normalization: false

replay_buffer:
  gae_lambda: ${rl_algo.gae_lambda}
  discount: ${rl_algo.discount}
  common: null
  skill:
    min_transitions: 25_000
    max_transitions: 1_000_000
    batch_size: 256
  policy:
    min_transitions: null
    max_transitions: 100_000
    batch_size: 64

trainer_args:
  n_parallel: 4
  on_policy_batch: 15
  traj_batch_size: 2
  skills_per_trajectory: 1
  n_epochs: 100_000
  trans_optimization_epochs: null
  skill_optimization_epochs: 50
  policy_optimization_mult: 10
  max_path_length: 999
  transitions_before_training: 25_000
  log_frequency: 5_000
  eval_frequency: 200_000