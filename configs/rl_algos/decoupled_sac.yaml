globals:
  device: 'cuda'
  sample_cpu: true
  seed: 42
  n_thread: 1
  n_parallel: 8
  mlp_arch: [512, 512]

env:
  name: maze
  max_path_length: 200
  frame_stack: null
  normalizer_type: "off"
  env_kwargs: null

skill:
  name: 'METRA'
  lr: 1e-4
  wd: 0.
  dim_option: 2
  discrete: false
  unit_length: true
  device: ${globals.device}
  dual_reg: true
  dual_slack: 1e-3
  dual_dist_name: 'one'
  dual_dist: null
  dual_lam: 30
  target_traj_encoder: 0.
  slot_pooler:
    name: Fetcher
    kwargs: {}
  trajectory_encoder:
    dim_option: ${skill.dim_option}
    net:
      hidden_sizes: ${globals.mlp_arch}
      hidden_nonlinearity: ReLU
    hypernet:
      hidden_sizes: ${globals.mlp_arch}
      hidden_nonlinearity: ReLU
      compressed_dim: 64
      parameterizer_dim: 12
      type: stupid

rl_algo:
  name: 'SAC'
  lr: 1e-4
  wd: 0.
  tau: 5e-3
  scale_reward: 1.
  target_coef: 1.
  discount: 0.99
  gae_lambda: null
  device: ${globals.device}
  slot_pooler:
    name: Transformer
    kwargs: 
      num_layers: 1
      nhead: 4
      dim_feedforward: 192
  policy:
    name: 'option_policy'
    dim_option: ${skill.dim_option}
    distribution_parameterization: TwoHeads
    normal_distribution_cls: TanhNormal
    init_std: 1.
    hidden_sizes: ${globals.mlp_arch}
    hidden_nonlinearity: Tanh
  critics:
    hidden_sizes: ${globals.mlp_arch}
    hidden_nonlinearity: ReLU
  alpha:
    value: 1e-2

replay_buffer:
  gae_lambda: ${rl_algo.gae_lambda}
  discount: ${rl_algo.discount}
  common:
    min_transitions: 10000
    max_transitions: 300000
    batch_size: 256
    discount: ${rl_algo.discount}
  skill: null
  policy: null

trainer_args:
  n_parallel: 4
  traj_batch_size: 8
  skills_per_trajectory: 1
  n_epochs: 100_000
  trans_optimization_epochs: 200
  skill_optimization_epochs: null
  policy_optimization_mult: null
  max_path_length: 25
  transitions_before_training: 10_000
  log_frequency: 50_000
  eval_frequency: 500_000